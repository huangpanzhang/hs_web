---
title: Our publications
subtitle: A list of our publications.
layout: "page"
icon: fa-book
order: 5
---

On Language Technology Lab, we have conducted multiple research projects in regard to hate speech. Our research interests lie on automatization of hate speech detection and how improvement and reliability in automated detection can be achieved. To do so, we have examined definitional and linguistic challenges and assessed how gender can play a role in hate speech detection. We have explored the development of monolingual and multilingual classification systems which can be used to identify and categorize offensive language on social media. We have generated a classification system to distinguish between free speech and language constituting a criminal offense. While our research focus lies on the technicality of hate speech, our aim is to take a more holistic approach by also taking social and legal aspects into consideration.

## Hate Speech Definitions

This research examines how reliability of hate speech annotations can be achieved based on the first German hate speech corpus on refugees. Our results suggest that detailed instructions for the annotation could be more useful than considering hate speech as a binary yes or no decision.

- [Björn Ross,  Michael Rist,  Guillermo Carbonell,  Ben-jamin  Cabrera,  Nils  Kurowsky,  and  Michael  Wo-jatzki.  2017.Measuring  the  Reliability  of  HateSpeech  Annotations:   The  Case  of  The  EuropeanRefugee Crisis.arXiv preprint arXiv:1701.08](https://arxiv.org/pdf/1701.08118.pdf)

## Significance of Implicitness in Hate Speech

The research explores whether implicitness affects the perception of hate speech. Our findings suggest that it is crucial to take implicitness into account when developing automated hate speech detection systems.

- [Darina Benikova, Michael Wojatzki, and Torsten Zesch. 2017. What Does This Imply? Examining the Impact of Implicitness on the Perception of Hate Speech. In International Conference of the German Society for Computational Linguistics and Language Technology, pages 171–179. Springer.](https://link.springer.com/chapter/10.1007/978-3-319-73706-5_14)

## Hate Speech towards Women

This study explores whether there is a relationship between perception of hate speech and gender by asking female and male subject to judge 400 assertions targeting women. The objective of the research is to find out whether being part of the targeted group or personal agreement with an assertion influence how hate speech is perceived. 

- [Michael Wojatzki, Tobias Horsmann, Darina Gold, and Torsten Zesch. 2018. Do Women Perceive Hate Differently: Examining the Relationship Between Hate Speech, Gender, and Agreement Judgments. In Proceedings of the Conference on Natural Language Processing (KONVENS), pages 110–120.](https://www.oeaw.ac.at/fileadmin/subsites/academiaecorpora/PDF/konvens18_13.pdf)

## Hate Speech Detection Systems

We participated on the SemEval 2019 Shared Task and made two contributions. The first contribution entailed building a system to predict multilingual hate speech posts and the second contribution was about how identification and categorization of offensive language on social media can be achieved. 

- [Huangpan Zhang, Michael Wojatzki, Tobias Horsmann, and Torsten Zesch. 2019. ltl.uni-due at semeval-2019 task 5: Simple but effective lexico-semantic features for detecting hate speech in twitter. In Proceedings of the 13th International Workshopon Semantic Evaluation, pages 441–446](https://www.aclweb.org/anthology/S19-2078.pdf)
- [Piush Aggarwal, Tobias Horsmann, Michael Wojatzki, and Torsten Zesch. 2019. Ltl-ude at semeval-2019 task 6: Bert and two-vote classification for categorizing offensiveness. In Proceedings of the 13th International Workshop on Semantic Evaluation, pages 678–682](https://www.aclweb.org/anthology/S19-2121.pdf)

## Classification of Criminal Offenses

We have generated an automated classification system to determine which Twitter posts would constitute a criminal offense under German criminal law using a data annotation schema that consists of a series of binary decision. Our findings suggest that the majority of posts fall under the category of morally offensive but do not constitute a criminal offense.

- [Frederike Zufall, Tobias Horsmann, and Torsten Zesch. 2019. From legal to technical concept: Towards anautomated classification of german political twitter postings as criminal offenses. In Proceedings of the2019 Conference of the North American Chapter ofthe Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 1337–134](https://www.aclweb.org/anthology/N19-1135.pdf)